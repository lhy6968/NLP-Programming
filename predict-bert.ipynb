{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import gzip\nimport json\n\n# Dataset: Clothing Fit Data (https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews)\n# 1. Modcloth (download link: https://datarepo.eng.ucsd.edu/mcauley_group/data/modcloth/modcloth_final_data.json.gz)\n# 2. RenttheRunway (download link: https://datarepo.eng.ucsd.edu/mcauley_group/data/renttherunway/renttherunway_final_data.json.gz)\n\n# modcloth_file = gzip.open('/content/modcloth_final_data.json.gz') # this dataset does not have reviews\n# modcloth_data = []\n# for mc_item in modcloth_file:\n#     modcloth_data.append(json.loads(mc_item))\n\n# renttherunway_file = gzip.open('/kaggle/input/renttherunway/renttherunway_final_data.json')\n\nrenttherunway_file = open('/kaggle/input/renttherunway/renttherunway_final_data.json')\n\nrenttherunway_data = []\nfor rtrw_item in renttherunway_file:\n  renttherunway_data.append(json.loads(rtrw_item))\n","metadata":{"id":"rku7mn0NOPrR","execution":{"iopub.status.busy":"2023-06-14T08:46:25.530003Z","iopub.execute_input":"2023-06-14T08:46:25.530567Z","iopub.status.idle":"2023-06-14T08:46:28.074402Z","shell.execute_reply.started":"2023-06-14T08:46:25.530530Z","shell.execute_reply":"2023-06-14T08:46:28.072956Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"print(\"renttherunway dataset size:\", len(renttherunway_data))\n# renttherunway_data = renttherunway_data[0:40000]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JgmyhJk3SgEx","outputId":"b8f445c9-7371-44e7-adfd-fa8177450242","execution":{"iopub.status.busy":"2023-06-14T08:46:28.076501Z","iopub.execute_input":"2023-06-14T08:46:28.076863Z","iopub.status.idle":"2023-06-14T08:46:28.082200Z","shell.execute_reply.started":"2023-06-14T08:46:28.076834Z","shell.execute_reply":"2023-06-14T08:46:28.081342Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"renttherunway dataset size: 192544\n","output_type":"stream"}]},{"cell_type":"code","source":"renttherunway_data = renttherunway_data[0:2000]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"009agY4nS00x","outputId":"167d1039-ccaf-4140-e371-b3347fedb967","execution":{"iopub.status.busy":"2023-06-14T08:46:28.083457Z","iopub.execute_input":"2023-06-14T08:46:28.083942Z","iopub.status.idle":"2023-06-14T08:46:28.294306Z","shell.execute_reply.started":"2023-06-14T08:46:28.083907Z","shell.execute_reply":"2023-06-14T08:46:28.293430Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# Confirm that the GPU is detected\n# torch.cuda.init()\n# assert torch.cuda.is_available()\n\n# Get the GPU device name.\n# device_name = torch.cuda.get_device_name()\n# n_gpu = torch.cuda.device_count()\n# print(f\"Found device: {device_name}, n_gpu: {n_gpu}\")\n# device = torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:46:28.296964Z","iopub.execute_input":"2023-06-14T08:46:28.297720Z","iopub.status.idle":"2023-06-14T08:46:28.305253Z","shell.execute_reply.started":"2023-06-14T08:46:28.297689Z","shell.execute_reply":"2023-06-14T08:46:28.304448Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Preprocess: extract only reviews and ratings, and remove null data\nreviews = []\nratings = []\nfor item in renttherunway_data:\n  if item['rating'] is not None and item['review_text'] is not None:\n    reviews.append(item['review_text'])\n    ratings.append(int(item['rating']))\n\nprint(\"dataset size after cleaning:\", len(reviews))\nprint(\"Mean of all ratings: \", round(sum(ratings) / len(ratings), 2))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uQqnL8jcUuyE","outputId":"4fff5066-8d0f-4411-e38a-f5f3c988bf2f","execution":{"iopub.status.busy":"2023-06-14T08:46:28.307040Z","iopub.execute_input":"2023-06-14T08:46:28.307955Z","iopub.status.idle":"2023-06-14T08:46:28.320930Z","shell.execute_reply.started":"2023-06-14T08:46:28.307916Z","shell.execute_reply":"2023-06-14T08:46:28.319960Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"dataset size after cleaning: 2000\nMean of all ratings:  9.05\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Data cleaning\n# import re\nimport pandas as pd\n\ndf = pd.DataFrame({'Review': reviews, 'Rating': ratings})","metadata":{"id":"Xds-xbj2Vtsb","execution":{"iopub.status.busy":"2023-06-14T08:46:28.322343Z","iopub.execute_input":"2023-06-14T08:46:28.323177Z","iopub.status.idle":"2023-06-14T08:46:28.335346Z","shell.execute_reply.started":"2023-06-14T08:46:28.323138Z","shell.execute_reply":"2023-06-14T08:46:28.334379Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport numpy as np\nfrom transformers import BertTokenizer, BertModel\nfrom torch import nn\nfrom torch.optim import Adam\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:46:28.336609Z","iopub.execute_input":"2023-06-14T08:46:28.337369Z","iopub.status.idle":"2023-06-14T08:46:28.348788Z","shell.execute_reply.started":"2023-06-14T08:46:28.337341Z","shell.execute_reply":"2023-06-14T08:46:28.347712Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"np.random.seed(112)\ndf_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n                                     [int(.8*len(df)), int(.9*len(df))])\n\nprint(len(df_train),len(df_val), len(df_test))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:46:28.350579Z","iopub.execute_input":"2023-06-14T08:46:28.351474Z","iopub.status.idle":"2023-06-14T08:46:28.372295Z","shell.execute_reply.started":"2023-06-14T08:46:28.351437Z","shell.execute_reply":"2023-06-14T08:46:28.371070Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"1600 200 200\n","output_type":"stream"}]},{"cell_type":"code","source":"# from transformers import BertTokenizer\n\n# tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n\n# example_text = 'I will watch Memento tonight. It is my favorite movie. I want to watch it again.'\n# bert_input = tokenizer(example_text,padding='max_length', max_length = 10, \n#                        truncation=True, return_tensors=\"pt\")\n\n\n# print(bert_input['input_ids'])\n# print(bert_input['token_type_ids'])\n# print(bert_input['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:46:28.374130Z","iopub.execute_input":"2023-06-14T08:46:28.374805Z","iopub.status.idle":"2023-06-14T08:46:28.380270Z","shell.execute_reply.started":"2023-06-14T08:46:28.374757Z","shell.execute_reply":"2023-06-14T08:46:28.378979Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n# labels = {'2':0,\n#           '4':1,\n#           '6':2,\n#           '8':3,\n#           '10':4\n#           }\n\nclass Dataset(torch.utils.data.Dataset):\n\n    def __init__(self, df):\n\n        self.labels = [np.float32(label) for label in df['Rating']]\n        self.texts = [tokenizer(text, \n                               padding='max_length', max_length = 512, truncation=True,\n                                return_tensors=\"pt\") for text in df['Review']]\n\n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def get_batch_labels(self, idx):\n        # Fetch a batch of labels\n        return np.array(self.labels[idx])\n\n    def get_batch_texts(self, idx):\n        # Fetch a batch of inputs\n        return self.texts[idx]\n\n    def __getitem__(self, idx):\n\n        batch_texts = self.get_batch_texts(idx)\n        batch_y = self.get_batch_labels(idx)\n\n        return batch_texts, batch_y","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:46:28.384701Z","iopub.execute_input":"2023-06-14T08:46:28.385214Z","iopub.status.idle":"2023-06-14T08:46:29.129467Z","shell.execute_reply.started":"2023-06-14T08:46:28.385176Z","shell.execute_reply":"2023-06-14T08:46:29.128281Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n\n    def __init__(self, dropout=0.5):\n\n        super(BertClassifier, self).__init__()\n\n        self.bert = BertModel.from_pretrained('bert-base-cased')\n        self.dropout = nn.Dropout(dropout)\n        self.linear = nn.Linear(768, 1)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_id, mask):\n\n        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n        dropout_output = self.dropout(pooled_output)\n        linear_output = self.linear(dropout_output)\n        final_layer = self.relu(linear_output)\n        \n\n        return final_layer","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:46:29.130918Z","iopub.execute_input":"2023-06-14T08:46:29.131366Z","iopub.status.idle":"2023-06-14T08:46:29.141611Z","shell.execute_reply.started":"2023-06-14T08:46:29.131316Z","shell.execute_reply":"2023-06-14T08:46:29.140465Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"def train(model, train_data, val_data, learning_rate, epochs):\n\n    train, val = Dataset(train_data), Dataset(val_data)\n\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n#     criterion = nn.CrossEntropyLoss()\n    criterion = nn.MSELoss()\n    optimizer = Adam(model.parameters(), lr = learning_rate)\n\n    if use_cuda:\n\n            model = model.cuda()\n            criterion = criterion.cuda()\n\n    for epoch_num in range(epochs):\n\n            total_loss_train = 0\n\n            for train_input, train_label in tqdm(train_dataloader):\n\n                train_label = train_label.to(device)\n                mask = train_input['attention_mask'].to(device)\n                input_id = train_input['input_ids'].squeeze(1).to(device)\n\n                output = model(input_id, mask).squeeze()\n#                 print(\"output:\",output)\n#                 print(\"train_label:\", train_label)\n                batch_loss = criterion(output, train_label)\n                total_loss_train += batch_loss.item()\n\n                model.zero_grad()\n                batch_loss.backward()\n                optimizer.step()\n            \n            total_loss_val = 0\n\n            with torch.no_grad():\n\n                for val_input, val_label in val_dataloader:\n\n                    val_label = val_label.to(device)\n                    mask = val_input['attention_mask'].to(device)\n                    input_id = val_input['input_ids'].squeeze(1).to(device)\n\n                    output = model(input_id, mask).squeeze()\n\n                    batch_loss = criterion(output, val_label)\n                    total_loss_val += batch_loss.item()\n                \n            \n            print(\n                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f}')\n                  ","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:46:29.143622Z","iopub.execute_input":"2023-06-14T08:46:29.144672Z","iopub.status.idle":"2023-06-14T08:46:29.160442Z","shell.execute_reply.started":"2023-06-14T08:46:29.144615Z","shell.execute_reply":"2023-06-14T08:46:29.159179Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n\nEPOCHS = 5\nmodel = BertClassifier()\nLR = 1e-5\n\nimport time\nstart = time.time()\n              \ntrain(model, df_train, df_val, LR, EPOCHS)\n\nend = time.time()\nprint(\"Elapsed Time: {:.2f} seconds\".format(end - start))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T08:46:29.161976Z","iopub.execute_input":"2023-06-14T08:46:29.162666Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n100%|██████████| 800/800 [1:13:41<00:00,  5.53s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 1 | Train Loss:  3.945 | Val Loss:  1.118\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 800/800 [1:12:59<00:00,  5.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 2 | Train Loss:  0.823 | Val Loss:  1.003\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 800/800 [1:12:53<00:00,  5.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 3 | Train Loss:  0.550 | Val Loss:  0.979\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 800/800 [1:13:18<00:00,  5.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 4 | Train Loss:  0.390 | Val Loss:  0.937\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 800/800 [1:13:01<00:00,  5.48s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate(model, test_data):\n\n    test = Dataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    criterion = nn.MSELoss()\n\n    if use_cuda:\n\n        model = model.cuda()\n\n    total_loss_test = 0\n    with torch.no_grad():\n\n        for test_input, test_label in test_dataloader:\n\n              test_label = test_label.to(device)\n              mask = test_input['attention_mask'].to(device)\n              input_id = test_input['input_ids'].squeeze(1).to(device)\n\n              output = model(input_id, mask).squeeze()\n            \n              batch_loss = criterion(output, test_label)\n              total_loss_test += batch_loss.item()\n              \n    \n    print(f'Val Loss: {total_loss_test / len(test_data): .3f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model, df_test)","metadata":{"execution":{"iopub.status.idle":"2023-06-14T15:10:15.372298Z","shell.execute_reply.started":"2023-06-14T15:07:16.913635Z","shell.execute_reply":"2023-06-14T15:10:15.371167Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Val Loss:  0.823\n","output_type":"stream"}]}]}